{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable Spatial to Numerical Transform\n",
    "An example of the usage of the DSNT layer, as taken from the paper \"Numerical Coordinate Regression with Convolutional Neural Networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sonnet as snt\n",
    "\n",
    "# Import for us of the transform layer and loss function\n",
    "import dsnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build some dummy data\n",
    "Circles of random colour, size and position on a black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "200 images total\n",
      "training: 150\n",
      "testing : 50\n"
     ]
    }
   ],
   "source": [
    "img_size = 150\n",
    "image_count = 200\n",
    "train_percent = 0.75\n",
    "train_image_count = int(train_percent * image_count)\n",
    "test_image_count = image_count - train_image_count\n",
    "\n",
    "images = []\n",
    "targets = []\n",
    "for _ in range(200):\n",
    "    img = np.zeros((img_size, img_size, 3))\n",
    "    row, col = np.random.randint(0, img_size), np.random.randint(0, img_size)\n",
    "    radius = np.random.randint(8, 15)\n",
    "    b, g, r = np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)\n",
    "    cv2.circle(img, (row, col), radius, (b, g, r), -1)\n",
    "    images.append(img)\n",
    "    norm_row = row / img_size\n",
    "    norm_col = col / img_size\n",
    "    targets.append([norm_row, norm_col])\n",
    "\n",
    "images = np.array(images)\n",
    "targets = np.array(targets)\n",
    "train_images = images[:train_image_count]\n",
    "test_images = images[train_image_count:]\n",
    "train_targets = targets[:train_image_count]\n",
    "test_targets = targets[train_image_count:]\n",
    "\n",
    "print('''\n",
    "{} images total\n",
    "training: {}\n",
    "testing : {}'''.format(image_count, train_image_count, test_image_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple model\n",
    "A handful of convolutional layers, each time downsampling by a factor of 2.\n",
    "The network finishes with a kernel-size 1 convolution, producing a single channel heat-map.\n",
    "I'm an advocate of [Deepmind's Sonnet](https://github.com/deepmind/sonnet), so the convolution operations are written using this. It's quite obvious what the equivalent Tensorflow operations would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(inputs):\n",
    "    inputs = snt.Conv2D(output_channels=166,\n",
    "                        kernel_shape=3,\n",
    "                        rate=1,\n",
    "                        padding='SAME',\n",
    "                        name='conv1')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=32,\n",
    "                        kernel_shape=3,\n",
    "                        rate=2,\n",
    "                        padding='SAME',\n",
    "                        name='conv2')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=64,\n",
    "                        kernel_shape=3,\n",
    "                        rate=4,\n",
    "                        padding='SAME',\n",
    "                        name='conv3')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=128,\n",
    "                        kernel_shape=3,\n",
    "                        rate=8,\n",
    "                        padding='SAME',\n",
    "                        name='conv4')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=256,\n",
    "                        kernel_shape=3,\n",
    "                        rate=16,\n",
    "                        padding='SAME',\n",
    "                        name='conv5')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=256,\n",
    "                        kernel_shape=3,\n",
    "                        padding='SAME',\n",
    "                        name='conv6')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=1,\n",
    "                        kernel_shape=1,\n",
    "                        padding='SAME',\n",
    "                        name='conv7')(inputs)\n",
    "    coords, norm_heatmap = dsnt.dsnt(inputs)\n",
    "    return coords, norm_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "A very simple training loop with no mini-batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.00449\n",
      "Testing MSE : 0.00745\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, 3])\n",
    "input_y = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "heatmaps, predictions = inference(input_x)\n",
    "# The predictions are in the range [-1, 1] but I prefer to work with [0, 1]\n",
    "predictions = (predictions + 1) / 2\n",
    "\n",
    "# Coordinate regression loss\n",
    "loss_1 = tf.losses.mean_squared_error(input_y, predictions)\n",
    "# Regularization loss\n",
    "loss_2 = dsnt.js_reg_loss(heatmaps, input_y)\n",
    "loss = loss_1 + loss_2\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=6e-5).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(10):\n",
    "        for i in range(train_image_count):\n",
    "            curr_img = train_images[i]\n",
    "            curr_target = train_targets[i]\n",
    "            _, loss_val = sess.run(\n",
    "                [optimizer, loss], \n",
    "                {\n",
    "                    input_x: [curr_img],\n",
    "                    input_y: [curr_target]\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def evaluate_total_mse(images, targets):\n",
    "        '''\n",
    "        Evaluate the mean-squared-error across the whole given batch of images, targets\n",
    "        '''\n",
    "        total_loss = 0\n",
    "        image_count = images.shape[0]\n",
    "        for i in range(image_count):\n",
    "            curr_img = images[i]\n",
    "            curr_target = targets[i]\n",
    "            loss_val = sess.run(loss_1, {\n",
    "                input_x: [curr_img],\n",
    "                input_y: [curr_target]\n",
    "            })\n",
    "            total_loss += loss_val\n",
    "        return total_loss / image_count\n",
    "\n",
    "    print(\"Training MSE: {:.5f}\".format(evaluate_total_mse(train_images, train_targets)))\n",
    "    print(\"Testing MSE : {:.5f}\".format(evaluate_total_mse(test_images, test_targets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
