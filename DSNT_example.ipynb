{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable Spatial to Numerical Transform\n",
    "An example of the usage of the DSNT layer, as taken from the paper \"Numerical Coordinate Regression with Convolutional Neural Networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sonnet as snt\n",
    "\n",
    "# Import for us of the transform layer and loss function\n",
    "import dsnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build some dummy data\n",
    "Circles of random colour, size and position on a black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_size = 150\n",
    "image_count = 200\n",
    "train_percent = 0.75\n",
    "train_image_count = int(train_percent * image_count)\n",
    "test_image_count = image_count - train_image_count\n",
    "\n",
    "images = []\n",
    "targets = []\n",
    "for _ in range(200):\n",
    "    img = np.zeros((img_size, img_size, 3))\n",
    "    row, col = np.random.randint(0, img_size), np.random.randint(0, img_size)\n",
    "    radius = np.random.randint(8, 15)\n",
    "    b, g, r = np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)\n",
    "    cv2.circle(img, (row, col), radius, (b, g, r), -1)\n",
    "    images.append(img)\n",
    "    norm_row = (row / img_size - 0.5) * 2\n",
    "    norm_col = (col / img_size - 0.5) * 2\n",
    "    targets.append([norm_row, norm_col])\n",
    "\n",
    "images = np.array(images)\n",
    "targets = np.array(targets)\n",
    "train_images = images[:train_image_count]\n",
    "test_images = images[train_image_count:]\n",
    "train_targets = targets[:train_image_count]\n",
    "test_targets = targets[train_image_count:]\n",
    "\n",
    "print('''\n",
    "{} images total\n",
    "training: {}\n",
    "testing : {}'''.format(image_count, train_image_count, test_image_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple model\n",
    "A handful of convolutional layers, each time downsampling by a factor of 2.\n",
    "The network finishes with a kernel-size 1 convolution, producing a single channel heat-map.\n",
    "I'm an advocate of [Deepmind's Sonnet](https://github.com/deepmind/sonnet), so the convolution operations are written using this. It's quite obvious what the equivalent Tensorflow operations would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(inputs):\n",
    "    inputs = snt.Conv2D(output_channels=166,\n",
    "                        kernel_shape=3,\n",
    "                        rate=1,\n",
    "                        padding='SAME',\n",
    "                        name='conv1')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=32,\n",
    "                        kernel_shape=3,\n",
    "                        rate=2,\n",
    "                        padding='SAME',\n",
    "                        name='conv2')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=64,\n",
    "                        kernel_shape=3,\n",
    "                        rate=4,\n",
    "                        padding='SAME',\n",
    "                        name='conv3')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=128,\n",
    "                        kernel_shape=3,\n",
    "                        rate=8,\n",
    "                        padding='SAME',\n",
    "                        name='conv4')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=256,\n",
    "                        kernel_shape=3,\n",
    "                        rate=16,\n",
    "                        padding='SAME',\n",
    "                        name='conv5')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=256,\n",
    "                        kernel_shape=3,\n",
    "                        padding='SAME',\n",
    "                        name='conv6')(inputs)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    inputs = tf.nn.max_pool(inputs, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    inputs = snt.Conv2D(output_channels=1,\n",
    "                        kernel_shape=1,\n",
    "                        padding='SAME',\n",
    "                        name='conv7')(inputs)\n",
    "    coords, norm_heatmap = dsnt.dsnt(inputs)\n",
    "    return coords, norm_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable Spatial to Numerical Transform\n",
    "A Tensorflow implementation of the DSNT layer, as taken from the paper \"Numerical Coordinate Regression with Convolutional Neural Networks\".\n",
    "\n",
    "### Provided Files:\n",
    "\n",
    "- `dsnt.py` - The layer implementation and its supporting functions\n",
    "- `DSNT_sample.ipynb` - A notebook demonstrating the usage of the DSNT layer.\n",
    "\n",
    "\n",
    "\n",
    "### Example usage:\n",
    "Begin by importing the module:\n",
    "```\n",
    "import dsnt\n",
    "```\n",
    "\n",
    "The layer can be inserted at the end of a stack of convolutional layers, where the final tensor shape is `[batch, height, width, 1]`.\n",
    "The function's input tensor will be rectified, then passed through the transform. `dsnt.dsnt` returns the rectified input heatmaps and the produced coordinates tensor of shape `[batch, x, y]`:\n",
    "```\n",
    "norm_heatmaps, coords = dsnt.dsnt(my_tensor)\n",
    "```\n",
    "There are different rectification methods available, which can be provided as an additional argument, e.g: `dsnt.normalise_heatmap(my_tensor, 'relu')`\n",
    "\n",
    "\n",
    "The loss function must be composed of two components. Mean-Squared-Error for the coordinate regression, and Jensen-Shannon Divergence for regularization.\n",
    "```\n",
    "# Coordinate regression loss\n",
    "loss_1 = tf.losses.mean_squared_error(targets, predictions)\n",
    "# Regularization loss - in this example the targets are in range [0, 1], \n",
    "# but need to be in range [-1, 1] for the regularization loss\n",
    "loss_2, target_gauss = dsnt.js_reg_loss(heatmaps, (targets + 1) / 2)\n",
    "\n",
    "loss = loss_1 + loss_2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "A very simple training loop with no mini-batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, 3])\n",
    "input_y = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "heatmaps, predictions = inference(input_x)\n",
    "loss_1 = tf.losses.mean_squared_error(input_y, predictions)\n",
    "# input_y is in the range [0, 1], but must be in range [-1, 1] for this loss\n",
    "loss_2, target_gauss = dsnt.js_reg_loss(heatmaps, (input_y + 1) / 2)\n",
    "loss = loss_1 + loss_2\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=6e-5).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for i in range(train_image_count):\n",
    "            curr_img = train_images[i]\n",
    "            curr_target = train_targets[i]\n",
    "            _, loss_val = sess.run(\n",
    "                [optimizer, loss], \n",
    "                {\n",
    "                    input_x: [curr_img],\n",
    "                    input_y: [curr_target]\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def evaluate_accuracy(images, targets):\n",
    "        '''\n",
    "        Evaluate the accuracy% across the whole given batch of images, targets\n",
    "        '''\n",
    "        total_loss = 0\n",
    "        image_count = images.shape[0]\n",
    "        for i in range(image_count):\n",
    "            curr_img = images[i]\n",
    "            curr_target = targets[i]\n",
    "            loss_val = sess.run(loss_1, {\n",
    "                input_x: [curr_img],\n",
    "                input_y: [curr_target]\n",
    "            })\n",
    "            total_loss += loss_val\n",
    "        return 1 - total_loss / image_count\n",
    "    \n",
    "    print(\"Training accuracy: {:.3f}%\".format(100 * evaluate_accuracy(train_images, train_targets)))\n",
    "    print(\"Testing accuracy : {:.3f}%\".format(100 * evaluate_accuracy(test_images, test_targets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
